{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d28140e-a0f1-453a-b74a-5e9b7155613f",
   "metadata": {},
   "source": [
    "**Temperature data analysis of the dune slacks**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad961d1e-ad10-4b67-88db-802008827ce0",
   "metadata": {},
   "source": [
    "The temperature data collected comes in two formats; .xls and .xlsx. The files with .xlsx format have 22 rows and the files with .xls have 28 rows, that contain general information of the data. Before processing the data, these rows should be removed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566e19c1-7c9b-4f16-b3c5-7a1ad91af5e0",
   "metadata": {},
   "source": [
    "**22 rows with .xlsx format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4d9c0e5d-84de-420c-9166-2931eb6777f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Directory path where the Excel files are located\n",always update the file location
    "directory = r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\" \n",
    "\n",
    "# Get the list of Excel file paths in the directory\n",
    "file_paths = glob.glob(directory + '/*.xlsx')  \n",
    "\n",
    "# Iterate over each file path\n",
    "for file_path in file_paths:\n",
    "    # Read the Excel file into a DataFrame, skipping the first 21 rows and excluding the header row\n",
    "    df = pd.read_excel(file_path, skiprows=22, header=None)\n",
    "   \n",
    "    # Save the modified DataFrame back to the Excel file, excluding the header row\n",
    "    df.to_excel(file_path, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936206a3-c6fd-4965-961c-de80310adb3e",
   "metadata": {},
   "source": [
    "**28 rows with .xls format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab6484-3b21-4509-9b45-1f42e0e58695",
   "metadata": {},
   "source": [
    "*After deleting the unnecessary rows the file is converted to .xlsx format to maintain consistency with the remaining files*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "f94d30ec-dd1e-4f53-87db-5db724c1b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\L18 Lente 2023 (3).xls to D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\L18 Lente 2023 (3).xlsx\n",
      "Converted D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\L18 Lente 2023 (4).xls to D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\L18 Lente 2023 (4).xlsx\n",
      "Converted D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\L18 Lente 2023 (5).xls to D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\L18 Lente 2023 (5).xlsx\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import xlrd\n",
    "from openpyxl import Workbook\n",
    "\n",
    "# Directory path where the Excel files are located\n",
    "directory = r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\" \n",
    "\n",
    "# Get the list of Excel file paths in the directory\n",
    "file_paths = glob.glob(directory + '/*.xls')  \n",
    "\n",
    "# Iterate over each file path\n",
    "for file_path in file_paths:\n",
    "    # Read the .xls file using xlrd\n",
    "    xls_workbook = xlrd.open_workbook(file_path)\n",
    "    \n",
    "    # Create a new .xlsx file\n",
    "    xlsx_file_path = file_path.replace('.xls', '.xlsx')\n",
    "    xlsx_workbook = Workbook()\n",
    "\n",
    "    # Iterate through sheets in the .xls workbook\n",
    "    for sheet_index in range(xls_workbook.nsheets):\n",
    "        xls_sheet = xls_workbook.sheet_by_index(sheet_index)\n",
    "        xlsx_sheet = xlsx_workbook.active if sheet_index == 0 else xlsx_workbook.create_sheet()\n",
    "\n",
    "        # Copy data from .xls sheet to .xlsx sheet\n",
    "        for row_index in range(xls_sheet.nrows):\n",
    "            row_data = xls_sheet.row_values(row_index)\n",
    "            xlsx_sheet.append(row_data)\n",
    "\n",
    "    # Save the .xlsx workbook\n",
    "    xlsx_workbook.save(xlsx_file_path)\n",
    "\n",
    "    print(f\"Converted {file_path} to {xlsx_file_path}\")\n",
    "    \n",
    "# Get the list of Excel file paths in the directory\n",
    "file_paths = glob.glob(directory + '/*.xlsx')  \n",
    "# Iterate over each file path\n",
    "for file_path in file_paths:\n",
    "    # Read the Excel file into a DataFrame, skipping the first 28 rows and excluding the header row\n",
    "    df = pd.read_excel(file_path, skiprows=28, header=None)\n",
    "    \n",
    "    # Save the modified DataFrame back to the Excel file, excluding the header row\n",
    "    df.to_excel(file_path, index=False, header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d252d29-0b6a-4cc9-b7c5-4052e3676c57",
   "metadata": {},
   "source": [
    "**Modify the date from yy-mm-dd to dd-mm-yyyy format**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b852ee3-8ce7-468d-b95b-fde6cc4f4954",
   "metadata": {},
   "source": [
    "*Most of the files come in the dd-mm-yyyy format. However, this is not the case in some files and thus need to be modified.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86deefa8-dc2c-4511-8177-bc406458d29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Directory path where the Excel files are located\n",
    "directory = r\"D:\\IHE\\Thesis\\Temperature\\metingen winter 2022_23\\Wimm L18 & L19\" \n",
    "\n",
    "# Get the list of Excel file paths in the directory\n",
    "file_paths = glob.glob(directory + '/*.xlsx')  \n",
    "\n",
    "# Iterate over each file path\n",
    "for file_path in file_paths:\n",
    "    # Read the Excel file into a DataFrame\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "    # Check if the 'Time' column exists in the DataFrame\n",
    "    if 'Time' in df.columns:\n",
    "        time_column = df['Time']\n",
    "\n",
    "        # Convert the 'Time' column to datetime type\n",
    "        df['Time'] = pd.to_datetime(time_column)\n",
    "\n",
    "        # Specify the desired datetime format\n",
    "        save_format = '%d-%m-%Y %H:%M:%S'  \n",
    "\n",
    "        # Format the datetime values in the 'Time' column\n",
    "        df['Time'] = df['Time'].dt.strftime(save_format)\n",
    "\n",
    "    # Save the modified DataFrame back to the Excel file\n",
    "    df.to_excel(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0081a80b-3554-48ec-984b-2703258ee514",
   "metadata": {},
   "source": [
    "**Combine excel files in a directory**\n",
    "\n",
    "Multiple files are present that contain the logged temperature values for a season. This files need to be combined in one file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "99467f5c-9337-4a54-ac30-70d7bdea66e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Specify the directory path containing the files\n",
    "directory_path = r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\" \n",
    "#specify the directory to save the combined files \n",
    "directory_path2 = r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\"\n",
    "# Get a list of all Excel files in the directory\n",
    "file_list = [file for file in os.listdir(directory_path) if file.endswith(\".xlsx\")]\n",
    "\n",
    "# Initialize an empty list to store DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through each file and read it into a DataFrame\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(directory_path, file)\n",
    "    df = pd.read_excel(file_path)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file\n",
    "output_file = os.path.join(directory_path2, \"Combined_Wimm.xlsx\")\n",
    "combined_df.to_excel(output_file, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88788500-6e50-4868-a382-2d77867e7198",
   "metadata": {},
   "source": [
    "**Extract night time temperature**\n",
    "\n",
    "Nocturnal temperature values are filtered out from the logged values. This is necessary to understand the nocturnal temperature course inside the dune slack. Night time hours may differ from season to season and it should be refered from valid website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "1331f788-6c77-41ff-835d-be63889df681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        No.                Time  Temperatureâ„ƒ\n",
      "118     119 2023-03-22 20:32:45           9.8\n",
      "119     120 2023-03-22 20:37:45          10.0\n",
      "120     121 2023-03-22 20:42:45          10.1\n",
      "121     122 2023-03-22 20:47:45          10.1\n",
      "122     123 2023-03-22 20:52:45          10.2\n",
      "...     ...                 ...           ...\n",
      "27875  7077 2023-06-27 06:38:15          16.4\n",
      "27876  7078 2023-06-27 06:43:15          16.3\n",
      "27877  7079 2023-06-27 06:48:15          16.2\n",
      "27878  7080 2023-06-27 06:53:15          16.3\n",
      "27879  7081 2023-06-27 06:58:15          16.6\n",
      "\n",
      "[12210 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yas001\\AppData\\Local\\Temp\\ipykernel_20624\\526746463.py:7: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  df['Time'] = pd.to_datetime(df['Time'], infer_datetime_format=True, dayfirst=True)\n",
      "C:\\Users\\yas001\\AppData\\Local\\Temp\\ipykernel_20624\\526746463.py:7: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  df['Time'] = pd.to_datetime(df['Time'], infer_datetime_format=True, dayfirst=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\Combined_Wimm.xlsx\")\n",
    "\n",
    "# Convert 'Time' column to datetime type\n",
    "df['Time'] = pd.to_datetime(df['Time'], infer_datetime_format=True, dayfirst=True)\n",
    "\n",
    "# Define the desired time range\n",
    "start_time = pd.to_datetime('20:30:00', format='%H:%M:%S').time()\n",
    "end_time = pd.to_datetime('07:00:00', format='%H:%M:%S').time()\n",
    "\n",
    "# Filter the DataFrame based on the date and time range\n",
    "filtered_df = df[\n",
    "    (df['Time'].dt.time >= start_time) | (df['Time'].dt.time <= end_time)\n",
    "]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "aaec51ad-7ded-46d7-bf32-c71cb99fe23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.to_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\Noctural_Wimm.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851d9a3-28f4-4255-8393-085e674c38ed",
   "metadata": {},
   "source": [
    "**Minimum temperature recorded**\n",
    "\n",
    "For a quick check of the lowest temperature recorded in a season. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "3ca73076-9007-4d47-bd51-b0977a4fa697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lowest temperature is: -11.1\n",
      "Row(s) with the lowest temperature:\n",
      "       No.                Time  Temperatureâ„ƒ\n",
      "1750  3975 2023-04-05 06:52:45         -11.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\Noctural_Wimm.xlsx\")  \n",
    "# Specify the column containing temperature values\n",
    "temperature_column = 'Temperatureâ„ƒ'  \n",
    "\n",
    "# Extract the lowest temperature value\n",
    "lowest_temperature = df[temperature_column].min() \n",
    "\n",
    "rows_with_lowest_temperature = df[df[temperature_column] == lowest_temperature]\n",
    "# Print the lowest temperature value\n",
    "print(f\"The lowest temperature is: {lowest_temperature}\")\n",
    "\n",
    "# Print the row(s) with the lowest temperature\n",
    "print(\"Row(s) with the lowest temperature:\")\n",
    "print(rows_with_lowest_temperature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d36235-027b-479b-8be9-024bdf11da82",
   "metadata": {},
   "source": [
    "**Extract the day of the cold air recorded**\n",
    "\n",
    "If the is a need to extract the night with the lowest recorded values. Sometimes useful to compare nearby dune slacks with each other on the same night."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e71aa60c-d8fb-495a-8f1d-e7ce96b8df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       No.                Time  Temperatureâ„ƒ\n",
      "1626  3851 2023-04-04 20:32:45           3.8\n",
      "1627  3852 2023-04-04 20:37:45           2.8\n",
      "1628  3853 2023-04-04 20:42:45           1.2\n",
      "1629  3854 2023-04-04 20:47:45          -0.4\n",
      "1630  3855 2023-04-04 20:52:45          -1.6\n",
      "1631  3856 2023-04-04 20:57:45          -2.5\n",
      "1632  3857 2023-04-04 21:02:45          -3.1\n",
      "1633  3858 2023-04-04 21:07:45          -3.6\n",
      "1634  3859 2023-04-04 21:12:45          -3.9\n",
      "1635  3860 2023-04-04 21:17:45          -4.4\n",
      "1636  3861 2023-04-04 21:22:45          -4.7\n",
      "1637  3862 2023-04-04 21:27:45          -4.9\n",
      "1638  3863 2023-04-04 21:32:45          -5.0\n",
      "1639  3864 2023-04-04 21:37:45          -5.1\n",
      "1640  3865 2023-04-04 21:42:45          -5.1\n",
      "1641  3866 2023-04-04 21:47:45          -5.2\n",
      "1642  3867 2023-04-04 21:52:45          -5.1\n",
      "1643  3868 2023-04-04 21:57:45          -5.2\n",
      "1644  3869 2023-04-04 22:02:45          -5.2\n",
      "1645  3870 2023-04-04 22:07:45          -5.1\n",
      "1646  3871 2023-04-04 22:12:45          -5.2\n",
      "1647  3872 2023-04-04 22:17:45          -5.3\n",
      "1648  3873 2023-04-04 22:22:45          -5.6\n",
      "1649  3874 2023-04-04 22:27:45          -5.9\n",
      "1650  3875 2023-04-04 22:32:45          -6.1\n",
      "1651  3876 2023-04-04 22:37:45          -6.3\n",
      "1652  3877 2023-04-04 22:42:45          -6.5\n",
      "1653  3878 2023-04-04 22:47:45          -6.6\n",
      "1654  3879 2023-04-04 22:52:45          -6.7\n",
      "1655  3880 2023-04-04 22:57:45          -6.8\n",
      "1656  3881 2023-04-04 23:02:45          -6.7\n",
      "1657  3882 2023-04-04 23:07:45          -6.8\n",
      "1658  3883 2023-04-04 23:12:45          -7.0\n",
      "1659  3884 2023-04-04 23:17:45          -6.9\n",
      "1660  3885 2023-04-04 23:22:45          -6.6\n",
      "1661  3886 2023-04-04 23:27:45          -6.0\n",
      "1662  3887 2023-04-04 23:32:45          -5.6\n",
      "1663  3888 2023-04-04 23:37:45          -5.6\n",
      "1664  3889 2023-04-04 23:42:45          -5.7\n",
      "1665  3890 2023-04-04 23:47:45          -5.7\n",
      "1666  3891 2023-04-04 23:52:45          -5.8\n",
      "1667  3892 2023-04-04 23:57:45          -5.8\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\Noctural_Wimm.xlsx\")\n",
    "\n",
    "# Convert 'Time' column to datetime type\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Define the desired date and time range. Time can is given upto midnight of the same day and the post midnight is extracted separately\n",
    "start_datetime = pd.to_datetime('2023-04-04  20:30:00', format='%Y-%m-%d %H:%M:%S')\n",
    "end_datetime = pd.to_datetime('2023-04-04  23:59:00', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Filter the DataFrame based on the date and time range\n",
    "filtered_df = df[\n",
    "    (df['Time'] >= start_datetime) &\n",
    "    (df['Time'] <= end_datetime)\n",
    "]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9f8f5576-5016-44da-b554-39ab820b7693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to a new Excel file\n",
    "filtered_df.to_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\04.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7bfe2c45-ba9b-42b5-b122-33033c130394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       No.                Time  Temperatureâ„ƒ\n",
      "1668  3893 2023-04-05 00:02:45          -5.7\n",
      "1669  3894 2023-04-05 00:07:45          -5.7\n",
      "1670  3895 2023-04-05 00:12:45          -5.7\n",
      "1671  3896 2023-04-05 00:17:45          -5.7\n",
      "1672  3897 2023-04-05 00:22:45          -5.6\n",
      "...    ...                 ...           ...\n",
      "1747  3972 2023-04-05 06:37:45         -11.0\n",
      "1748  3973 2023-04-05 06:42:45         -11.0\n",
      "1749  3974 2023-04-05 06:47:45         -11.0\n",
      "1750  3975 2023-04-05 06:52:45         -11.1\n",
      "1751  3976 2023-04-05 06:57:45         -11.0\n",
      "\n",
      "[84 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\Noctural_Wimm.xlsx\")\n",
    "\n",
    "# Convert 'Time' column to datetime type\n",
    "df['Time'] = pd.to_datetime(df['Time'], format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Define the desired date and time range\n",
    "start_datetime = pd.to_datetime('2023-04-05   00:00:00', format='%Y-%m-%d %H:%M:%S')\n",
    "end_datetime = pd.to_datetime('2023-04-05  07:00:00', format='%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Filter the DataFrame based on the date and time range\n",
    "filtered_df = df[\n",
    "    (df['Time'] >= start_datetime) &\n",
    "    (df['Time'] <= end_datetime)\n",
    "]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7c6a3487-1b80-4f5b-ad0a-8a64b0e54bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the filtered DataFrame to a new Excel file\n",
    "filtered_df.to_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\05.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09e0c3c-a3bc-46dc-a873-47fcd1b5524c",
   "metadata": {},
   "source": [
    "**Concatenate**\n",
    "\n",
    "Combine the extracted files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2ae96aec-a97d-4b45-bf28-45f56f19b2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the '16.xlsx' and '17.xlsx' files into DataFrames\n",
    "df_16 = pd.read_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\04.xlsx\")\n",
    "df_17 = pd.read_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\05.xlsx\")\n",
    "\n",
    "# Concatenate the two DataFrames\n",
    "combined_df = pd.concat([df_16, df_17], ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a new Excel file/\n",
    "combined_df.to_excel(r\"D:\\IHE\\Thesis\\Temperature\\ruwe data lente 2023\\Wimm L18 & L19\\Output\\Coldestday_Wimm.xlsx\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126f43d-6a6f-49ae-9171-fa7d3b7892cb",
   "metadata": {},
   "source": [
    "**Corrections**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74af0dc8-a49d-4364-b6ea-a6866396572e",
   "metadata": {},
   "source": [
    "*To apply temperature corrections to the extracted files based on different values. This values are given separtely in a file named corrections*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34954475-df80-4c5d-af20-fb87b7d52136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted temperatures saved to Nocturnal_Diep.xlsx\n",
      "All files processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Replace 'directory_path' with the actual path to the directory containing your Excel files\n",
    "directory_path = r'D:\\IHE\\Thesis\\Temperature\\metingen winter 2022_23\\Berg Diep L14 & L15\\Outputs\\New folder'\n",
    "\n",
    "# Define correction values based on temperature ranges\n",
    "correction_values = {\n",
    "    '< -10': - 0.2,\n",
    "    '[-10;-5]': 0.1,\n",
    "    '[-5;0]': 0.1,\n",
    "    '[0;15]': 0.2,\n",
    "    '[15;20]': 0.2,\n",
    "    '> 20': 0.2\n",
    "}\n",
    "# L14\t-0.2\t0.1\t0.1\t0.2\t0.2\n",
    "def apply_correction(temperature):\n",
    "    for range_, correction in correction_values.items():\n",
    "        if '[' in range_:\n",
    "            min_val, max_val = map(float, range_[1:-1].split(';'))\n",
    "            if min_val <= temperature <= max_val:\n",
    "                return temperature + correction\n",
    "        elif '<' in range_:\n",
    "            max_val = float(range_[1:])\n",
    "            if temperature < max_val:\n",
    "                return temperature - correction\n",
    "        elif '>' in range_:\n",
    "            min_val = float(range_[1:])\n",
    "            if temperature > min_val:\n",
    "                return temperature + correction\n",
    "    return temperature\n",
    "\n",
    "# Iterate through files in the directory\n",
    "for filename in os.listdir(directory_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Load the Excel file into a DataFrame\n",
    "        data = pd.read_excel(file_path, engine='openpyxl')\n",
    "        \n",
    "        # Apply correction to the 'Temperatureâ„ƒ' column\n",
    "        data['Corrected'] = data['Temperatureâ„ƒ'].apply(apply_correction)\n",
    "        \n",
    "        # Save the DataFrame with corrected values to the same Excel file\n",
    "        data.to_excel(file_path, index=False, engine='openpyxl')\n",
    "        \n",
    "        print(f\"Adjusted temperatures saved to {filename}\")\n",
    "\n",
    "print(\"All files processed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
